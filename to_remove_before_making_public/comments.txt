# Comments for COMP30024 AI Project B Submission

`Therrense Lua (student number: 782578)`  
`Tianlei Zheng (student number: 773109)`

>>>>>>>>>>>>>>>>>>>>>>> IMPORTANT <<<<<<<<<<<<<<<<<<<<<<<
Python module minimax_player (in `minimax_player.py` located 
at the root of our submitted files) should be used for grading. 

e.g. 
```
python referee.py minimax_player some_other_ai
```

This file is just a wrapper, the actual implementation is located at 
`ai/agents/minimax.py`, as explained below.

## Explaination of file structure:

```
|-- ai	-> Our main module `ai`, most of the AI code is located here
    |-- agents	-> Module `ai.agents` contains our actual AI agents. Mostly wrappers around AI algorithms + handles the details like keeping track of states in between turns.
        |-- minimax.py  -> player based on minimax with alpha-beta pruning (the one we choose for submission)
        |-- mc.py       -> player based on Monte Carlo Tree search (not used)
        |-- dummy.py    -> a random-moves player (for testing; not used)
        |-- mirror.py   -> a player that mirrors the opponent's moves (for testing; not used)
        |-- playerbase.py -> A shared base class for our different players, handles keeping track of state and communication with `referee.py`
        ...
    |-- algos	-> This module `ai.algos` contains our implementations of AI algorithms. They are decoupled (mostly) from the game-specific concerns
        |-- mc  -> Monte Carlo Tree Search algorithm
            ...
        |-- minimax.py  -> minimax algorithm with alpha-beta pruning
    |-- commons	-> This module `ai.common` contains the shared logic and utilities
        |-- lazy_board.py   -> board and game logic 
        |-- test_*.py       -> unit tests
        |-- ...
|-- minimax_player.py  -> a wrapper file that re-exports our Player class, to work around strange Python relative module resolution issues
|-- *_player.py	        -> wrapper files, similar to above
|-- ...


## What we have done.

1. First of all, we implemented and released WYB-online (A Human vs Human playground) at http://wyb.radiumz.org/
    - This allowed us to familarised with the game rules and test out a couple of strategies manually.
    - hopefully, deserve some credit for pro-activeness, more details below

2. Optimisations made to our minimax algorithm
    i. our evaluation/heuristic function valued different positions on the board by their importance/weightage
        - we valued the inner part of the board at a higher weightage 
    ii. we also utilised different search depths depending on the phase of the game
        - by searching deeper when the board shrinked twice
    iii. we reduce our search space by avoiding moving pieces that form squares in the middle of the board as it was more advantageous to hold those positions to the late game
        - this enabled us to search deeper into the tree

    iv. our miniMax made use of alpha-beta pruning to not search into redundant branches
    v. we also stored and check game states that are similar to avoid re-searching

3. Implementation techniques
    - in our board logic implementation (lazy_board.py)
        i. we use compact byte arrays to reduce memory usage (eg. as arrays.arrays)
        ii. we store deltas/changes, and only lazily apply them when need (hence the name "LazyBoard")
        iii. we use hash value (LazyBoard.get_hash_value) to provide a way of keeping track of existing states efficiently (O(1) lookup)

4. search algorithms not taught in class
    i. We implemented a basic Monte Carlo Tree Search, but it wasn't performing as good as minimax.
        - We did not have time to push the performance further.

5. unit testing
    i. We wrote Unit tests to ensure our game logic is correct and consistent while we refactor the code

6. special classes used to compete/optimise minimax_player
    i. dummy_player - makes random moves
    ii. mirror_player - mirrors opponent's moves

misc. did not have time to do
    i. TDLeaf search
    ii. SSS* (sorting game tree for faster discovery)


## Additional Tools we built and used

1. wyb-online (Source code in wyb-online.zip): 
    The online human-vs-human gaming platform for Watch Your Back! 
    Built in JavaScript with Socket.io & Vue.js and deployed at http://wyb.radiumz.org

    It took us over a week to built the server-side logic and the UI, we basically 
    re-implemented the game logic in JavaScript and take into account of multiple
    simultaneous players.
    
    This tool has benefited not only us but other teams as well. 

2. bakeoff.py: 
    Allows us to run bake-offs (basically rounds of play-outs) between different versions of our AI,
    get an idea of how they perform (in terms of winning rates) against each other.

3. perf.py:
    We used cProfile to find bottlenecks in our code, and verify that our modifications do improve
    the performance.